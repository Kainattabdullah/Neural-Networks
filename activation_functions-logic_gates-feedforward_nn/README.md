
This project covers the foundational concepts of Artificial Neural Networks (ANN) through practical exercises, including the implementation of activation functions, logic gates, and a feedforward neural network with backpropagation. 

## Contents
1. **Activation Functions**
   - Introduction to activation functions and their importance in ANN.
   - Types of activation functions: Linear, Sigmoid, Tanh, ReLU, Leaky ReLU, Softmax.
  
2. **Logic Gates Implementation**
   - Implementing basic logic gates (AND, OR, XOR) using the perceptron training rule.

3. **Feedforward Neural Network**
   - Structure and training of a feedforward neural network using backpropagation.
   - Examples of binary classification using the Iris dataset.

4. **Exercise Questions**
   - Practical tasks to plot activation functions and compare their performance in classification tasks using the Wine Quality dataset.

## Requirements
Make sure to have the following libraries installed:
- `numpy`
- `matplotlib`
- `tensorflow`
- `scikit-learn`

You can install these using pip:
```bash
pip install numpy matplotlib tensorflow scikit-learn